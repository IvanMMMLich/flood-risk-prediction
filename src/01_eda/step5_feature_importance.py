"""
===============================================================================
                    STEP 5: FEATURE IMPORTANCE ANALYSIS
                    
                    –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
===============================================================================

–¶–ï–õ–¨:
-----
1. –ò–∑–º–µ—Ä–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ Mutual Information
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ Permutation Importance
3. –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
4. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏

–†–ï–ó–£–õ–¨–¢–ê–¢:
---------
- –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ—Ü–µ–Ω–∫–∏
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—Ç–±–æ—Ä—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.inspection import permutation_importance
from sklearn.ensemble import RandomForestClassifier

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
ROOT_DIR = Path(__file__).parent.parent.parent
DATA_PROCESSED = ROOT_DIR / 'data' / 'processed'
RESULTS = ROOT_DIR / 'results' / 'step5_importance'
RESULTS.mkdir(parents=True, exist_ok=True)

def load_and_prepare_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏."""
    print("\n" + "="*60)
    print("STEP 5: FEATURE IMPORTANCE ANALYSIS")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv(DATA_PROCESSED / 'train_cleaned.csv')
    print(f"\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ X –∏ y
    X = df.drop(['id', 'loan_status'], axis=1)
    y = df['loan_status']
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    le_dict = {}
    categorical_cols = X.select_dtypes(include=['object']).columns
    
    print("\nüîß –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for col in categorical_cols:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        le_dict[col] = le
        print(f"   {col}: {len(le.classes_)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    
    return X, y, le_dict

def calculate_mutual_information(X, y):
    """–†–∞—Å—á–µ—Ç Mutual Information Score."""
    print("\nüìä MUTUAL INFORMATION SCORE:")
    print("="*40)
    print("(–°–∫–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–∞—Ä–≥–µ—Ç–µ –¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫)")
    print("-"*40)
    
    # –†–∞—Å—á–µ—Ç MI scores
    mi_scores = mutual_info_classif(X, y, random_state=42)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    mi_df = pd.DataFrame({
        'feature': X.columns,
        'mi_score': mi_scores
    }).sort_values('mi_score', ascending=False)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (0-1)
    mi_df['mi_normalized'] = mi_df['mi_score'] / mi_df['mi_score'].max()
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI:")
    for idx, row in mi_df.head(10).iterrows():
        bar = '‚ñà' * int(row['mi_normalized'] * 20)
        print(f"{row['feature']:25s}: {row['mi_score']:.4f} {bar}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(10, 8))
    top_15 = mi_df.head(15)
    colors = ['red' if x > 0.5 else 'orange' if x > 0.25 else 'green' 
              for x in top_15['mi_normalized']]
    
    plt.barh(range(len(top_15)), top_15['mi_score'], color=colors)
    plt.yticks(range(len(top_15)), top_15['feature'])
    plt.xlabel('Mutual Information Score')
    plt.title('Feature Importance by Mutual Information')
    plt.gca().invert_yaxis()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –ø–æ–ª–æ—Å–∫–∏
    for i, (idx, row) in enumerate(top_15.iterrows()):
        plt.text(row['mi_score'] + 0.001, i, f'{row["mi_score"]:.4f}', 
                va='center')
    
    plt.tight_layout()
    plt.savefig(RESULTS / 'mutual_information.png', dpi=100, bbox_inches='tight')
    plt.show()
    
    return mi_df

def calculate_permutation_importance(X, y):
    """–†–∞—Å—á–µ—Ç Permutation Importance."""
    print("\nüìä PERMUTATION IMPORTANCE:")
    print("="*40)
    print("(–ù–∞—Å–∫–æ–ª—å–∫–æ —É–ø–∞–¥–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞)")
    print("-"*40)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # –û–±—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
    print("\n–û–±—É—á–∞–µ–º LogisticRegression –¥–ª—è –æ—Ü–µ–Ω–∫–∏...")
    model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
    model.fit(X_train, y_train)
    
    # –†–∞—Å—á–µ—Ç permutation importance
    print("–í—ã—á–∏—Å–ª—è–µ–º permutation importance (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–∏–Ω—É—Ç—É)...")
    perm_importance = permutation_importance(
        model, X_val, y_val, 
        n_repeats=10, 
        random_state=42,
        scoring='roc_auc'
    )
    
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    perm_df = pd.DataFrame({
        'feature': X.columns,
        'importance': perm_importance.importances_mean,
        'std': perm_importance.importances_std
    }).sort_values('importance', ascending=False)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Permutation Importance:")
    for idx, row in perm_df.head(10).iterrows():
        bar = '‚ñà' * int((row['importance'] / perm_df['importance'].max()) * 20)
        print(f"{row['feature']:25s}: {row['importance']:.4f} ¬± {row['std']:.4f} {bar}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(10, 8))
    top_15 = perm_df.head(15)
    
    plt.barh(range(len(top_15)), top_15['importance'], 
            xerr=top_15['std'], color='steelblue', alpha=0.7)
    plt.yticks(range(len(top_15)), top_15['feature'])
    plt.xlabel('Permutation Importance')
    plt.title('Feature Importance by Permutation')
    plt.gca().invert_yaxis()
    
    plt.tight_layout()
    plt.savefig(RESULTS / 'permutation_importance.png', dpi=100, bbox_inches='tight')
    plt.show()
    
    return perm_df

def calculate_forest_importance(X, y):
    """–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ Random Forest."""
    print("\nüìä RANDOM FOREST FEATURE IMPORTANCE:")
    print("="*40)
    print("(–í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –∏–∑ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π)")
    print("-"*40)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # –û–±—É—á–∞–µ–º Random Forest
    print("\n–û–±—É—á–∞–µ–º Random Forest...")
    rf_model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
    rf_df = pd.DataFrame({
        'feature': X.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ Random Forest:")
    for idx, row in rf_df.head(10).iterrows():
        bar = '‚ñà' * int((row['importance'] / rf_df['importance'].max()) * 20)
        print(f"{row['feature']:25s}: {row['importance']:.4f} {bar}")
    
    return rf_df

def compare_methods(mi_df, perm_df, rf_df):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏."""
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í:")
    print("="*40)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    comparison = pd.DataFrame({
        'feature': mi_df['feature'],
        'mutual_info_rank': range(1, len(mi_df) + 1),
        'mi_score': mi_df['mi_score'].values
    })
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–Ω–≥–∏ –∏–∑ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–æ–≤
    perm_ranks = {feat: rank+1 for rank, feat in enumerate(perm_df['feature'])}
    rf_ranks = {feat: rank+1 for rank, feat in enumerate(rf_df['feature'])}
    
    comparison['perm_rank'] = comparison['feature'].map(perm_ranks)
    comparison['rf_rank'] = comparison['feature'].map(rf_ranks)
    
    # –°—Ä–µ–¥–Ω–∏–π —Ä–∞–Ω–≥
    comparison['avg_rank'] = comparison[['mutual_info_rank', 'perm_rank', 'rf_rank']].mean(axis=1)
    comparison = comparison.sort_values('avg_rank')
    
    print("\n–°–û–ì–õ–ê–°–û–í–ê–ù–ù–´–ô –¢–û–ü-10 (–ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —Ä–∞–Ω–≥—É):")
    print("-"*50)
    print(f"{'–ü—Ä–∏–∑–Ω–∞–∫':<25} {'MI':>5} {'Perm':>5} {'RF':>5} {'Avg':>6}")
    print("-"*50)
    
    for idx, row in comparison.head(10).iterrows():
        print(f"{row['feature']:<25} {row['mutual_info_rank']:5.0f} "
              f"{row['perm_rank']:5.0f} {row['rf_rank']:5.0f} "
              f"{row['avg_rank']:6.1f}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # –¢–æ–ø-10 –ø–æ –∫–∞–∂–¥–æ–º—É –º–µ—Ç–æ–¥—É
    methods = [
        ('Mutual Information', mi_df.head(10)),
        ('Permutation Importance', perm_df.head(10)),
        ('Random Forest', rf_df.head(10))
    ]
    
    for ax, (method_name, data) in zip(axes, methods):
        ax.barh(range(10), data.iloc[:, 1], color='skyblue')
        ax.set_yticks(range(10))
        ax.set_yticklabels(data['feature'])
        ax.set_title(method_name)
        ax.invert_yaxis()
    
    plt.tight_layout()
    plt.savefig(RESULTS / 'methods_comparison.png', dpi=100, bbox_inches='tight')
    plt.show()
    
    return comparison

def create_recommendations(comparison):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ—Ç–±–æ—Ä—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("="*40)
    
    # –¢–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–º—É —Ä–∞–Ω–≥—É
    top_features = comparison.head(10)['feature'].tolist()
    
    print("\n–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–æ–ø-5):")
    for i, feat in enumerate(top_features[:5], 1):
        print(f"   {i}. {feat}")
    
    print("\n–í–ê–ñ–ù–´–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ (6-10):")
    for i, feat in enumerate(top_features[5:10], 6):
        print(f"   {i}. {feat}")
    
    print("\n–í–û–ó–ú–û–ñ–ù–û –£–î–ê–õ–ò–¢–¨ (–Ω–∏–∑–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å):")
    bottom_features = comparison.tail(3)['feature'].tolist()
    for feat in bottom_features:
        print(f"   - {feat}")
    
    print("\nüìå –í–´–í–û–î–´:")
    print("-"*40)
    print("1. loan_percent_income - –ö–†–ò–¢–ò–ß–ï–°–ö–ò –≤–∞–∂–µ–Ω")
    print("2. loan_int_rate - –≤—Ç–æ—Ä–æ–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏")
    print("3. loan_grade - –∫–ª—é—á–µ–≤–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π")
    print("4. –í–æ–∑—Ä–∞—Å—Ç –∏ –¥–æ—Ö–æ–¥ - —É–º–µ—Ä–µ–Ω–Ω–æ –≤–∞–∂–Ω—ã")
    print("5. cb_person_cred_hist_length - –º–æ–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å")
    
    return top_features

def save_results(mi_df, perm_df, rf_df, comparison, top_features):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã
    mi_df.to_csv(RESULTS / 'mutual_information.csv', index=False)
    perm_df.to_csv(RESULTS / 'permutation_importance.csv', index=False)
    rf_df.to_csv(RESULTS / 'random_forest_importance.csv', index=False)
    comparison.to_csv(RESULTS / 'methods_comparison.csv', index=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    with open(RESULTS / 'top_features.txt', 'w') as f:
        f.write("TOP FEATURES FOR MODEL:\n")
        f.write("="*30 + "\n")
        for i, feat in enumerate(top_features, 1):
            f.write(f"{i}. {feat}\n")
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {RESULTS}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X, y, le_dict = load_and_prepare_data()
    
    # –†–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    mi_df = calculate_mutual_information(X, y)
    perm_df = calculate_permutation_importance(X, y)
    rf_df = calculate_forest_importance(X, y)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    comparison = compare_methods(mi_df, perm_df, rf_df)
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    top_features = create_recommendations(comparison)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_results(mi_df, perm_df, rf_df, comparison, top_features)
    
    print("\n" + "="*60)
    print("STEP 5 COMPLETED!")
    print("="*60)
    print("‚úÖ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑–º–µ—Ä–µ–Ω–∞ —Ç—Ä–µ–º—è –º–µ—Ç–æ–¥–∞–º–∏")
    print("‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏")
    print("‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—Ç–±–æ—Ä—É")
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {RESULTS}")

if __name__ == "__main__":
    main()