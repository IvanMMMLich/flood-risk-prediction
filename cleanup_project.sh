#!/bin/bash

echo "================================================"
echo "üßπ –û–ß–ò–°–¢–ö–ê –ò –û–†–ì–ê–ù–ò–ó–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê"
echo "================================================"

# –ü–µ—Ä–µ—Ö–æ–¥ –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
cd ~/VSCODE/loan-approval-prediction

echo ""
echo "1Ô∏è‚É£ –£–î–ê–õ–ï–ù–ò–ï –ü–£–°–¢–´–• –ò –ù–ï–ù–£–ñ–ù–´–• –ü–ê–ü–û–ö..."
echo "----------------------------------------"

# –£–¥–∞–ª—è–µ–º —Ç–æ—á–Ω–æ –Ω–µ–Ω—É–∂–Ω—ã–µ –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
rm -rf models/
rm -rf scripts/
rm -rf tests/
rm -rf notebooks/
rm -rf results/tables/
rm -rf results/figures/
rm -rf results/reports/
rm -rf results/features/
rm -rf results/step1_first_look/
rm -rf results/step6_engineering/
rm -rf src/04_evaluation/
rm -rf data/submissions/  # —Å—Ç–∞—Ä–∞—è –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞
echo "‚úÖ –ü—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ —É–¥–∞–ª–µ–Ω—ã"

echo ""
echo "2Ô∏è‚É£ –£–î–ê–õ–ï–ù–ò–ï –°–ò–°–¢–ï–ú–ù–´–• –§–ê–ô–õ–û–í..."
echo "----------------------------------------"

# –£–¥–∞–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –º—É—Å–æ—Ä Mac
find . -name ".DS_Store" -delete
find . -name "*.pyc" -delete  
find . -name "__pycache__" -type d -delete
find . -name ".ipynb_checkpoints" -type d -delete
echo "‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã"

echo ""
echo "3Ô∏è‚É£ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´..."
echo "----------------------------------------"

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É step2
if [ -f "results/step2_deep_explore/categorical_features_statistics.csv" ]; then
    mv results/step2_deep_explore/categorical_features_statistics.csv results/step2_deep_explore/categorical_features/
    echo "‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω categorical_features_statistics.csv"
fi

if [ -f "results/step2_deep_explore/numeric_features_statistics.csv" ]; then
    mv results/step2_deep_explore/numeric_features_statistics.csv results/step2_deep_explore/numeric_features/
    echo "‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω numeric_features_statistics.csv"
fi

echo ""
echo "4Ô∏è‚É£ –°–û–ó–î–ê–ù–ò–ï –í–ê–ñ–ù–´–• –§–ê–ô–õ–û–í..."
echo "----------------------------------------"

# –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∫–æ—Ä–µ–Ω—å
if [ -f "results/model_versions/v3_final/model.pkl" ]; then
    cp results/model_versions/v3_final/model.pkl ./final_model.pkl
    echo "‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –≤ –∫–æ—Ä–µ–Ω—å"
fi

# –û–±–Ω–æ–≤–ª—è–µ–º .gitignore
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/

# Data (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –¥–ª—è git)
data/raw/*.csv
!data/raw/sample_submission.csv

# Models (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã)
*.pkl
*.joblib
*.h5

# System files
.DS_Store
Thumbs.db
.vscode/
.idea/
*.log
*.swp

# Jupyter
.ipynb_checkpoints/
*.ipynb

# Temporary
tmp/
temp/
EOF
echo "‚úÖ .gitignore –æ–±–Ω–æ–≤–ª–µ–Ω"

echo ""
echo "5Ô∏è‚É£ –°–û–ó–î–ê–ù–ò–ï README –î–õ–Ø –í–ê–ñ–ù–´–• –ü–ê–ü–û–ö..."
echo "----------------------------------------"

# README –¥–ª—è submissions
cat > submissions/README.md << 'EOF'
# Submission Files

## Latest Results
- **File:** submission_latest.csv
- **ROC-AUC:** 0.9535
- **Model:** Random Forest + XGBoost
- **Date:** 2025-11-21

## How to Submit
1. Go to Kaggle competition page
2. Upload `submission_latest.csv`
3. Wait for scoring

## History
- v3_final: ROC-AUC 0.9535 (XGBoost)
- v2_engineered: ROC-AUC 0.9316 (Random Forest)
- v1_cleaned: ROC-AUC 0.8730 (Logistic Regression)
- v0_baseline: ROC-AUC 0.8740 (Baseline)
EOF
echo "‚úÖ README –¥–ª—è submissions —Å–æ–∑–¥–∞–Ω"

# README –¥–ª—è data
cat > data/README.md << 'EOF'
# Data Directory Structure

## Folders
- **raw/** - Original data from Kaggle
- **processed/** - Cleaned data (anomalies fixed)
- **engineered/** - Feature engineered data (final)

## Data Pipeline
1. raw ‚Üí processed (Step 3: cleaning)
2. processed ‚Üí engineered (Step 6: feature engineering)
3. engineered ‚Üí model training (Step 7)

## File Sizes
- train.csv: 58,645 records
- test.csv: 39,098 records
EOF
echo "‚úÖ README –¥–ª—è data —Å–æ–∑–¥–∞–Ω"

# README –¥–ª—è results
cat > results/README.md << 'EOF'
# Results Directory

## Model Versions
- **v0_baseline** - Initial baseline (ROC-AUC: 0.8740)
- **v1_after_cleaning** - After data cleaning (ROC-AUC: 0.8730)
- **v2_after_engineering** - After feature engineering (ROC-AUC: 0.9316)
- **v3_final** - Final model with XGBoost (ROC-AUC: 0.9535)

## Analysis Steps
- **step2_deep_explore** - Detailed EDA
- **step3_cleaning** - Data quality checks
- **step4_target** - Target variable analysis
- **step5_importance** - Feature importance analysis
- **final_model** - Final model artifacts
EOF
echo "‚úÖ README –¥–ª—è results —Å–æ–∑–¥–∞–Ω"

echo ""
echo "6Ô∏è‚É£ –°–û–ó–î–ê–ù–ò–ï –§–ê–ô–õ–ê requirements.txt..."
echo "----------------------------------------"

cat > requirements.txt << 'EOF'
# Data Processing
pandas==2.3.3
numpy==2.3.5

# Visualization
matplotlib==3.10.2
seaborn==0.13.2

# Machine Learning
scikit-learn==1.6.1
xgboost==3.1.2

# Utilities
jupyter==1.1.1
ipython==8.31.0
EOF
echo "‚úÖ requirements.txt –æ–±–Ω–æ–≤–ª–µ–Ω"

echo ""
echo "7Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê –°–¢–†–£–ö–¢–£–†–´..."
echo "----------------------------------------"

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
echo ""
echo "üìÅ –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê:"
echo ""
tree -L 2 -I 'venv|__pycache__|*.pyc' 2>/dev/null || ls -la

echo ""
echo "================================================"
echo "‚úÖ –û–ß–ò–°–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!"
echo "================================================"
echo ""
echo "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:"
echo "- –ú–æ–¥–µ–ª—å: ROC-AUC 0.9535"
echo "- Submission: –≥–æ—Ç–æ–≤ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ"
echo "- –†–∞–∑–º–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞: $(du -sh . | cut -f1)"
echo ""
echo "üöÄ –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ GitHub!"
echo ""
